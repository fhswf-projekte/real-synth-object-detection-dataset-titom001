{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4fd285-4169-4515-a5f9-f8b48aec5c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from pycocotools) (1.24.4)\n",
      "Downloading pycocotools-2.0.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (477 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m477.3/477.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.10\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660be363-c2fe-45d5-8f11-101e5257735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import CocoDetection\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1264b3cb-d7fc-4122-be92-49af69b3aa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"synth\"\n",
    "ann_file = \"synth/synth_image_annotations.json\"\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = CocoDetection(root=image_dir, annFile=ann_file, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413107fd-9a1b-44e1-9737-c54ee6afd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_target(target):\n",
    "    \"\"\"\n",
    "    Konvertiert eine Liste von COCO-Annotationen in das Format,\n",
    "    das vom Faster R-CNN erwartet wird:\n",
    "      - \"boxes\": [x_min, y_min, x_max, y_max]\n",
    "      - \"labels\": Kategorie-IDs\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    for obj in target:\n",
    "        bbox = obj[\"bbox\"]  # Format: [x, y, width, height]\n",
    "        boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
    "        labels.append(obj[\"category_id\"])\n",
    "    if len(boxes) == 0:\n",
    "        boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "        labels = torch.zeros((0,), dtype=torch.int64)\n",
    "    else:\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "    return {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, targets = list(zip(*batch))\n",
    "    images = list(images)\n",
    "    targets = [convert_target(t) for t in targets]\n",
    "    return images, targets\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d1a7d81-1add-46cc-9479-316ab8ece9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoche 1/10, durchschnittlicher Loss: 24.9315\n",
      "Epoche 2/10, durchschnittlicher Loss: 14.5345\n",
      "Epoche 3/10, durchschnittlicher Loss: 11.9186\n",
      "Epoche 4/10, durchschnittlicher Loss: 9.3234\n",
      "Epoche 5/10, durchschnittlicher Loss: 7.9085\n",
      "Epoche 6/10, durchschnittlicher Loss: 7.0247\n",
      "Epoche 7/10, durchschnittlicher Loss: 6.2426\n",
      "Epoche 8/10, durchschnittlicher Loss: 5.4677\n",
      "Epoche 9/10, durchschnittlicher Loss: 4.7587\n",
      "Epoche 10/10, durchschnittlicher Loss: 4.6294\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.train()\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for images, targets in dataloader:\n",
    "\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += losses.item()\n",
    "\n",
    "    print(f\"Epoche {epoch+1}/{num_epochs}, durchschnittlicher Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e083c-1c15-4edf-aac7-c8c22d0add55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
