{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2712f097-a744-4346-b8f3-e47ab18576a4",
   "metadata": {},
   "source": [
    "Für die Ausführung dieses Notebooks wird ein HugginFace Account, ein Token und die Bestätigung der Lizenzen der folgenden Modelle benötigt um diese verwenden zu können.\n",
    "* https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307f251-8e2f-4e7f-b294-9beb6c883edb",
   "metadata": {},
   "source": [
    "Wir müssen die diffusers Bibliothek manuell aus dem Git-Repository installieren, damit die HiDreamPipeline verfügbar ist. Anschließend muss der Kernel neugestartet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3c501f-edf4-455d-8012-87e41c994390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/diffusers.git\n",
      "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-j_d8zfrq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-j_d8zfrq\n",
      "  Resolved https://github.com/huggingface/diffusers.git to commit 6ab62c743183fff206239af931921908ae3ce133\n",
      "  Installing build dependencies ... \u001b[?done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib_metadata in /opt/conda/lib/python3.11/site-packages (from diffusers==0.34.0.dev0) (6.8.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from diffusers==0.34.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.27.0 in /opt/conda/lib/python3.11/site-packages (from diffusers==0.34.0.dev0) (0.29.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from diffusers==0.34.0.dev0) (1.24.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from diffusers==0.34.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from diffusers==0.34.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from diffusers==0.34.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from diffusers==0.34.0.dev0) (10.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.27.0->diffusers==0.34.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib_metadata->diffusers==0.34.0.dev0) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers==0.34.0.dev0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers==0.34.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers==0.34.0.dev0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers==0.34.0.dev0) (2023.7.22)\n",
      "Building wheels for collected packages: diffusers\n",
      "  Building wheel for diffusers (pyproject.toml) ... done\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.34.0.dev0-py3-none-any.whl size=3601997 sha256=59adc167127f1bbf25e959bf6a9c01f32cc79c1b755a5e04fa8d282998820779\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yjm6z68h/wheels/d2/5c/5f/16639722ea17ecb73ab461b81718584bac08af2801619786b9\n",
      "Successfully built diffusers\n",
      "Installing collected packages: diffusers\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.32.2\n",
      "    Uninstalling diffusers-0.32.2:\n",
      "      Successfully uninstalled diffusers-0.32.2\n",
      "Successfully installed diffusers-0.34.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/diffusers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3c698b-3664-4007-ac09-693d24fa95cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5130cbc-89f3-4960-9523-f1936a15d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import login\n",
    "from diffusers import DiffusionPipeline, HiDreamImagePipeline, FluxPipeline, StableDiffusion3Pipeline\n",
    "from transformers import PreTrainedTokenizerFast, LlamaForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46501a5f-9881-49fb-9e6b-b3179b49c8ca",
   "metadata": {},
   "source": [
    "Hier HF-Token bereithalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e97a6d2-4782-4df5-b037-c76b43139f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e584be0ccf6c487a9a01fac0de965365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1557809-cb1f-461b-9909-62d5afa38ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"a hyperrealistic photo of a group of musicians playing various instruments in a band, set in a random location\",\n",
    "    \"a hyperrealistic photo of a common living room with a variety of music instrument scattered around the room\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a1be15-1405-431a-bfbc-6eb1c3256baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(pipe, model_prompts, model_name, guidance_scale, steps, move_to_gpu=True):\n",
    "    if guidance_scale < 2.1:\n",
    "        print('guidance_scale must be greater than 2.0')\n",
    "    \n",
    "    generator = torch.Generator(\"cuda\").manual_seed(0)\n",
    "\n",
    "    try:\n",
    "        if move_to_gpu:\n",
    "            pipe = pipe.to('cuda')\n",
    "        g_scales = [guidance_scale-2, guidance_scale, guidance_scale+2]\n",
    "\n",
    "        for index, prompt in enumerate(model_prompts):\n",
    "            for gs in g_scales:\n",
    "                image = pipe(\n",
    "                    prompt,\n",
    "                    height=1024,\n",
    "                    width=1024,\n",
    "                    guidance_scale=gs,\n",
    "                    num_inference_steps=steps,\n",
    "                    max_sequence_length=512,\n",
    "                    generator=generator,\n",
    "                ).images[0]\n",
    "                steps_string = str(steps).replace('.', '-')\n",
    "                image.save(f\"./eval_files/{model_name}_prompt-{index}_guidance-{gs}_steps-{steps_string}.png\")\n",
    "                print('Run successfully')\n",
    "    finally:\n",
    "        print('Moving pipe to cpu and empty cache')\n",
    "        pipe.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "        del pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "179301ed-7154-4374-9d1f-119ce9913b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b4d0e731de441eb7831164cd7a72f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d483851434614e15b7745c23e040c770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 33 files:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f98531324674fe8acdd38d05fa1ccb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/876 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f35f82350d24445ac596069baf2e402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3e9b78d2ac4956989e4228d641e16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60afba36ef014b1c9f4d0197852f7dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55f21f5e66d4affa034edd07e6f41d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a370c324f542d0884c4ba617acb7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadc5cca2fe94a8da2d06258dd126de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0d10b8fe5144dcbbb2382c21219ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88445f307ac94572983f8e1fc6e13de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9153727e074c9aa768cb2c447a9ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n",
      "Moving pipe to cpu and empty cache\n"
     ]
    }
   ],
   "source": [
    "# HiDream-ai/HiDream-I1-Full\n",
    "\n",
    "tokenizer_4 = PreTrainedTokenizerFast.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "text_encoder_4 = LlamaForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    output_hidden_states=True,\n",
    "    output_attentions=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "hidream_full_pipe = HiDreamImagePipeline.from_pretrained(\n",
    "    \"HiDream-ai/HiDream-I1-Full\",\n",
    "    tokenizer_4=tokenizer_4,\n",
    "    text_encoder_4=text_encoder_4,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "hidream_full_pipe.enable_model_cpu_offload()\n",
    "hidream_full_pipe.enable_vae_tiling()\n",
    "\n",
    "run_model(hidream_full_pipe, prompts, \"HiDream-I1-Full\", 5.0, 50, False)\n",
    "del hidream_full_pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6899cb-e121-4f9a-9839-00579d411e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ead221d5977498e844d0343d12409b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78544fd7152a44fb93805cbe091e1ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f839672a6054303b87b21afab59c27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abe649dd6654a6abc23ae63c4814eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900e8e2700204723bb1b54aa3b2e8b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6bc07a7c564d8a8b5c9ddb898ad1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76743b5c9ae342bf9f8ee341dee9dbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0430bc3b32c34dd1b69de4caeb18c1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd5bc4fbb694e4ea6da3006f59e43f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n",
      "Moving pipe to cpu and empty cache\n"
     ]
    }
   ],
   "source": [
    "# black-forest-labs/FLUX.1-dev\n",
    "\n",
    "flux_pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "run_model(flux_pipe, prompts, \"FLUX-1-dev\", 3.5, 50)\n",
    "del flux_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a85a517-ce28-490d-ac50-703677b5c549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f22e8682564e069a8f8e4ae164d118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64ab8d769e4478fbcb19ef8c2450f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494ee69ad1dc478eb2412199b78ef44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f450916f8c42e3a49930a46e3d4908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e5fd3de9fb437ea086de71bb3f1df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09afb95571944fa59658532b5168457c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103a0b5d19544d399b3617b933966c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0244848782db4359a400f6bb5a3cfbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d25f0f2aac14f808eb4adddd8fc71c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n",
      "Moving pipe to cpu and empty cache\n"
     ]
    }
   ],
   "source": [
    "# stabilityai/stable-diffusion-3.5-large\n",
    "\n",
    "sd35_pipe = StableDiffusion3Pipeline.from_pretrained(\"stabilityai/stable-diffusion-3.5-large\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "run_model(sd35_pipe, prompts, \"sd35\", 3.5, 28)\n",
    "del sd35_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0056d438-df6f-4a65-8b1d-dd4c8edd11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedSDXLPipe:\n",
    "    def __init__(self, high_noise_frac):\n",
    "        self.high_noise_frac = high_noise_frac\n",
    "        self.base = DiffusionPipeline.from_pretrained(\n",
    "            \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    "        )\n",
    "        \n",
    "        self.refiner = DiffusionPipeline.from_pretrained(\n",
    "            \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "            text_encoder_2=self.base.text_encoder_2,\n",
    "            vae=self.base.vae,\n",
    "            torch_dtype=torch.float16,\n",
    "            use_safetensors=True,\n",
    "            variant=\"fp16\",\n",
    "        )\n",
    "\n",
    "    def to(self, device):\n",
    "        self.base.to(device)\n",
    "        self.refiner.to(device)\n",
    "        return self\n",
    "\n",
    "    def __call__(self, prompt, width, height, guidance_scale, num_inference_steps, max_sequence_length, generator):\n",
    "        image = self.base(\n",
    "            prompt=prompt,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            guidance_scale=guidance_scale,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            denoising_end=self.high_noise_frac,\n",
    "            output_type=\"latent\",\n",
    "            generator=generator\n",
    "        ).images\n",
    "        return self.refiner(\n",
    "            prompt=prompt,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            guidance_scale=guidance_scale,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            denoising_start=self.high_noise_frac,\n",
    "            image=image,\n",
    "            generator=generator\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d1f8150-1da2-4e9e-8261-5230cbcd6486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d91672764f54fb0be21c021b97bc097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5d05f528234708a50ad77158ed8ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b006a6a7722e433b9117b23f2ed9e6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7982e2358374f63a123cd8e07ba5fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c455dabf2e491c88aea3dc89213774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af19a1175524185b78339abff4cf2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8df759de3fa41de8ced9893fa79da8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0060523fd2fd47f2b3cc6ebcb68dfe41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8259233619a9480a854ecd86113651f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01823f1ede1a44ed9c3d128758a99ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb1764cd94f44629f0202353f8c2b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca78947398849749b9731457e0c8466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f67735920f4f0982227cd11aa4914c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e747c3e9ea0243e99bb66b0616e1402d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run successfully\n",
      "Moving pipe to cpu and empty cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    }
   ],
   "source": [
    "# stabilityai/stable-diffusion-xl-base-1.0\n",
    "\n",
    "sdxl_pipe = CombinedSDXLPipe(0.8)\n",
    "run_model(sdxl_pipe, prompts, \"sdxlrefiner\", 7.5, 40)\n",
    "del sdxl_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62504887-6b84-411c-a00b-440f2104ada8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
